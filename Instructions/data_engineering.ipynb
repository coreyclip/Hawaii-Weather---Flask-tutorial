{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stations = pd.read_csv('resources/hawaii_stations.csv')\n",
    "measures = pd.read_csv('resources/hawaii_measurements.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19550 entries, 0 to 19549\n",
      "Data columns (total 4 columns):\n",
      "station    19550 non-null object\n",
      "date       19550 non-null object\n",
      "prcp       18103 non-null float64\n",
      "tobs       19550 non-null int64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 611.0+ KB\n"
     ]
    }
   ],
   "source": [
    "measures.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "it looks like we have some missing percipitation data \n",
    "\n",
    "I can see two logical methods for dealing with this\n",
    "1. either fill in the missing values with the average across the entire variable\n",
    "2. input in the median between the prior date and the next date\n",
    "\n",
    "I'm going to opt for the later option as it seems to make more sense considering that we are working with weather data organized as a time series. \n",
    "\n",
    "Let's start by marking our rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        station        date  prcp  tobs  nulls\n",
      "0   USC00519397  2010-01-01  0.08    65  False\n",
      "1   USC00519397  2010-01-02  0.00    63  False\n",
      "2   USC00519397  2010-01-03  0.00    74  False\n",
      "3   USC00519397  2010-01-04  0.00    76  False\n",
      "4   USC00519397  2010-01-06   NaN    73   True\n",
      "5   USC00519397  2010-01-07  0.06    70  False\n",
      "6   USC00519397  2010-01-08  0.00    64  False\n",
      "7   USC00519397  2010-01-09  0.00    68  False\n",
      "8   USC00519397  2010-01-10  0.00    73  False\n",
      "9   USC00519397  2010-01-11  0.01    64  False\n",
      "10  USC00519397  2010-01-12  0.00    61  False\n",
      "11  USC00519397  2010-01-14  0.00    66  False\n",
      "12  USC00519397  2010-01-15  0.00    65  False\n",
      "13  USC00519397  2010-01-16  0.00    68  False\n",
      "14  USC00519397  2010-01-17  0.00    64  False\n",
      "15  USC00519397  2010-01-18  0.00    72  False\n",
      "16  USC00519397  2010-01-19  0.00    66  False\n",
      "17  USC00519397  2010-01-20  0.00    66  False\n",
      "18  USC00519397  2010-01-21  0.00    69  False\n",
      "19  USC00519397  2010-01-22  0.00    67  False\n",
      "20  USC00519397  2010-01-23  0.00    67  False\n",
      "21  USC00519397  2010-01-24  0.01    71  False\n",
      "22  USC00519397  2010-01-25  0.00    67  False\n",
      "23  USC00519397  2010-01-26  0.04    76  False\n",
      "24  USC00519397  2010-01-27  0.12    68  False\n",
      "25  USC00519397  2010-01-28  0.00    72  False\n",
      "26  USC00519397  2010-01-30   NaN    70   True\n",
      "27  USC00519397  2010-01-31  0.03    67  False\n",
      "28  USC00519397  2010-02-01  0.01    66  False\n",
      "29  USC00519397  2010-02-03   NaN    67   True\n",
      "30  USC00519397  2010-02-04  0.01    69  False\n",
      "31  USC00519397  2010-02-05  0.00    67  False\n",
      "32  USC00519397  2010-02-06  0.00    67  False\n",
      "33  USC00519397  2010-02-07  0.00    64  False\n",
      "34  USC00519397  2010-02-08  0.00    69  False\n",
      "35  USC00519397  2010-02-09  0.00    73  False\n",
      "36  USC00519397  2010-02-11  0.00    73  False\n",
      "37  USC00519397  2010-02-12  0.02    69  False\n",
      "38  USC00519397  2010-02-13  0.01    69  False\n",
      "39  USC00519397  2010-02-14  0.00    69  False\n"
     ]
    }
   ],
   "source": [
    "measures['nulls'] = measures.isnull().any(axis=1)\n",
    "print(measures.head(40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pandas Interpolate function to fill in the missing values\n",
    "\n",
    "Pandas has an interpolate method that fills in missing values as the median between the previous row and the next row \n",
    " \n",
    "We can see what values were changed by looking for rows where 'nulls' == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           station        date      prcp  tobs  nulls\n",
      "0      USC00519397  2010-01-01  0.080000    65  False\n",
      "1      USC00519397  2010-01-02  0.000000    63  False\n",
      "2      USC00519397  2010-01-03  0.000000    74  False\n",
      "3      USC00519397  2010-01-04  0.000000    76  False\n",
      "4      USC00519397  2010-01-06  0.030000    73   True\n",
      "5      USC00519397  2010-01-07  0.060000    70  False\n",
      "6      USC00519397  2010-01-08  0.000000    64  False\n",
      "7      USC00519397  2010-01-09  0.000000    68  False\n",
      "8      USC00519397  2010-01-10  0.000000    73  False\n",
      "9      USC00519397  2010-01-11  0.010000    64  False\n",
      "10     USC00519397  2010-01-12  0.000000    61  False\n",
      "11     USC00519397  2010-01-14  0.000000    66  False\n",
      "12     USC00519397  2010-01-15  0.000000    65  False\n",
      "13     USC00519397  2010-01-16  0.000000    68  False\n",
      "14     USC00519397  2010-01-17  0.000000    64  False\n",
      "15     USC00519397  2010-01-18  0.000000    72  False\n",
      "16     USC00519397  2010-01-19  0.000000    66  False\n",
      "17     USC00519397  2010-01-20  0.000000    66  False\n",
      "18     USC00519397  2010-01-21  0.000000    69  False\n",
      "19     USC00519397  2010-01-22  0.000000    67  False\n",
      "20     USC00519397  2010-01-23  0.000000    67  False\n",
      "21     USC00519397  2010-01-24  0.010000    71  False\n",
      "22     USC00519397  2010-01-25  0.000000    67  False\n",
      "23     USC00519397  2010-01-26  0.040000    76  False\n",
      "24     USC00519397  2010-01-27  0.120000    68  False\n",
      "25     USC00519397  2010-01-28  0.000000    72  False\n",
      "26     USC00519397  2010-01-30  0.015000    70   True\n",
      "27     USC00519397  2010-01-31  0.030000    67  False\n",
      "28     USC00519397  2010-02-01  0.010000    66  False\n",
      "29     USC00519397  2010-02-03  0.010000    67   True\n",
      "...            ...         ...       ...   ...    ...\n",
      "19520  USC00516128  2017-07-24  0.840000    77  False\n",
      "19521  USC00516128  2017-07-25  0.300000    79  False\n",
      "19522  USC00516128  2017-07-26  0.300000    73  False\n",
      "19523  USC00516128  2017-07-27  0.000000    75  False\n",
      "19524  USC00516128  2017-07-28  0.400000    73  False\n",
      "19525  USC00516128  2017-07-29  0.300000    77  False\n",
      "19526  USC00516128  2017-07-30  0.300000    79  False\n",
      "19527  USC00516128  2017-07-31  0.000000    74  False\n",
      "19528  USC00516128  2017-08-01  0.125000    72   True\n",
      "19529  USC00516128  2017-08-02  0.250000    80  False\n",
      "19530  USC00516128  2017-08-03  0.060000    76  False\n",
      "19531  USC00516128  2017-08-05  0.056667    77   True\n",
      "19532  USC00516128  2017-08-06  0.053333    79   True\n",
      "19533  USC00516128  2017-08-07  0.050000    78  False\n",
      "19534  USC00516128  2017-08-08  0.340000    74  False\n",
      "19535  USC00516128  2017-08-09  0.150000    71  False\n",
      "19536  USC00516128  2017-08-10  0.070000    75  False\n",
      "19537  USC00516128  2017-08-11  0.105000    72   True\n",
      "19538  USC00516128  2017-08-12  0.140000    74  False\n",
      "19539  USC00516128  2017-08-13  0.180000    80   True\n",
      "19540  USC00516128  2017-08-14  0.220000    79  False\n",
      "19541  USC00516128  2017-08-15  0.420000    70  False\n",
      "19542  USC00516128  2017-08-16  0.420000    71  False\n",
      "19543  USC00516128  2017-08-17  0.130000    72  False\n",
      "19544  USC00516128  2017-08-18  0.110000    76   True\n",
      "19545  USC00516128  2017-08-19  0.090000    71  False\n",
      "19546  USC00516128  2017-08-20  0.325000    78   True\n",
      "19547  USC00516128  2017-08-21  0.560000    76  False\n",
      "19548  USC00516128  2017-08-22  0.500000    76  False\n",
      "19549  USC00516128  2017-08-23  0.450000    76  False\n",
      "\n",
      "[19550 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "measures = measures.interpolate()    \n",
    "print(measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we just have to save the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures.to_csv('resources/clean_measures.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
